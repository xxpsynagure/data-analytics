{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpl7pQFMHvu+wQ7pzEPNs3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xxpsynagure/data-analytics/blob/main/Pragnya_4SO19CS110_BDA_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BDA Lab Assignment 2\n",
        "\n",
        "## 1.  MapReduce program in Java to find occurrences of each word in a text file.\n",
        "\n",
        "### Step 1: Set up the environment and Start the Hadoop Server"
      ],
      "metadata": {
        "id": "C-WwgerS_Vs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\""
      ],
      "metadata": {
        "id": "ofejLoSO6RrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/hadoop-3.3.4/bin/hadoop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chg33ntn6_Qw",
        "outputId": "19ea68aa-3612-4bc9-8fea-8a210eee3452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: hadoop [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]\n",
            " or    hadoop [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]\n",
            "  where CLASSNAME is a user-provided Java class\n",
            "\n",
            "  OPTIONS is none or any of:\n",
            "\n",
            "buildpaths                       attempt to add class files from build tree\n",
            "--config dir                     Hadoop config directory\n",
            "--debug                          turn on shell script debug mode\n",
            "--help                           usage information\n",
            "hostnames list[,of,host,names]   hosts to use in slave mode\n",
            "hosts filename                   list of hosts to use in slave mode\n",
            "loglevel level                   set the log4j level for this command\n",
            "workers                          turn on worker mode\n",
            "\n",
            "  SUBCOMMAND is one of:\n",
            "\n",
            "\n",
            "    Admin Commands:\n",
            "\n",
            "daemonlog     get/set the log level for each daemon\n",
            "\n",
            "    Client Commands:\n",
            "\n",
            "archive       create a Hadoop archive\n",
            "checknative   check native Hadoop and compression libraries availability\n",
            "classpath     prints the class path needed to get the Hadoop jar and the\n",
            "              required libraries\n",
            "conftest      validate configuration XML files\n",
            "credential    interact with credential providers\n",
            "distch        distributed metadata changer\n",
            "distcp        copy file or directories recursively\n",
            "dtutil        operations related to delegation tokens\n",
            "envvars       display computed Hadoop environment variables\n",
            "fs            run a generic filesystem user client\n",
            "gridmix       submit a mix of synthetic job, modeling a profiled from\n",
            "              production load\n",
            "jar <jar>     run a jar file. NOTE: please use \"yarn jar\" to launch YARN\n",
            "              applications, not this command.\n",
            "jnipath       prints the java.library.path\n",
            "kdiag         Diagnose Kerberos Problems\n",
            "kerbname      show auth_to_local principal conversion\n",
            "key           manage keys via the KeyProvider\n",
            "rumenfolder   scale a rumen input trace\n",
            "rumentrace    convert logs into a rumen trace\n",
            "s3guard       manage metadata on S3\n",
            "trace         view and modify Hadoop tracing settings\n",
            "version       print the version\n",
            "\n",
            "    Daemon Commands:\n",
            "\n",
            "kms           run KMS, the Key Management Server\n",
            "registrydns   run the registry DNS server\n",
            "\n",
            "SUBCOMMAND may print help when invoked w/o parameters or with -h.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Write Mapper and Reducer Program in Java and create a jar file"
      ],
      "metadata": {
        "id": "Fw4g_njr_qbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/input\n",
        "!mkdir ~/MapReduce"
      ],
      "metadata": {
        "id": "QKr__aAu7E6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ~/MapReduce/mapper.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cAYXPCY_tnD",
        "outputId": "62b94fed-617b-47e1-ae8b-dc167bf19221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/usr/bin/env python\r\n",
            "\"\"\"mapper.py\"\"\"\r\n",
            "\r\n",
            "import sys\r\n",
            "\r\n",
            "# input comes from STDIN (standard input)\r\n",
            "for line in sys.stdin:\r\n",
            "    # remove leading and trailing whitespace\r\n",
            "    line = line.strip()\r\n",
            "    # split the line into words\r\n",
            "    words = line.split()\r\n",
            "    # increase counters\r\n",
            "    for word in words:\r\n",
            "        # write the results to STDOUT (standard output);\r\n",
            "        # what we output here will be the input for the\r\n",
            "        # Reduce step, i.e. the input for reducer.py\r\n",
            "        #\r\n",
            "        # tab-delimited; the trivial word count is 1\r\n",
            "        print('%s\\t%s' % (word, 1))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ~/MapReduce/reducer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW6AbX7YAgLp",
        "outputId": "0cf6f445-d13d-4e9b-8583-8f75f2f6bbba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/usr/bin/env python\r\n",
            "\"\"\"reducer.py\"\"\"\r\n",
            "\r\n",
            "from operator import itemgetter\r\n",
            "import sys\r\n",
            "\r\n",
            "current_word = None\r\n",
            "current_count = 0\r\n",
            "word = None\r\n",
            "\r\n",
            "# input comes from STDIN\r\n",
            "for line in sys.stdin:\r\n",
            "    # remove leading and trailing whitespace\r\n",
            "    line = line.strip()\r\n",
            "\r\n",
            "    # parse the input we got from mapper.py\r\n",
            "    word, count = line.split('\\t', 1)\r\n",
            "\r\n",
            "    # convert count (currently a string) to int\r\n",
            "    try:\r\n",
            "        count = int(count)\r\n",
            "    except ValueError:\r\n",
            "        # count was not a number, so silently\r\n",
            "        # ignore/discard this line\r\n",
            "        continue\r\n",
            "\r\n",
            "    # this IF-switch only works because Hadoop sorts map output\r\n",
            "    # by key (here: word) before it is passed to the reducer\r\n",
            "    if current_word == word:\r\n",
            "        current_count += count\r\n",
            "    else:\r\n",
            "        if current_word:\r\n",
            "            # write result to STDOUT\r\n",
            "            print('%s\\t%s' % (current_word, current_count))\r\n",
            "        current_count = count\r\n",
            "        current_word = word\r\n",
            "\r\n",
            "# do not forget to output the last word if needed!\r\n",
            "if current_word == word:\r\n",
            "    print('%s\\t%s' % (current_word, current_count))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat > ~/input/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_h3mgeh8tHD",
        "outputId": "143057dd-07b6-42d0-8664-e414bd44525b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good Morning\n",
            "Good Afternoon\n",
            "Good Evening\n",
            "Good Night\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Provide permission to the files added."
      ],
      "metadata": {
        "id": "gkrRxbdNA3FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod u+rwx /root/MapReduce/mapper.py\n",
        "!chmod u+rwx /root/MapReduce/reducer.py"
      ],
      "metadata": {
        "id": "DaS45Q4U9KNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Test your programs"
      ],
      "metadata": {
        "id": "ZC4VUK80BTCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo Good Morning Good Evening Good Night | python /root/MapReduce/mapper.py | sort | python /root/MapReduce/reducer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9BMtfhIBZzO",
        "outputId": "23899782-4656-46d3-9a7b-e989c069e31e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evening\t1\n",
            "Good\t3\n",
            "Morning\t1\n",
            "Night\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Run the command to perform Map Reduce using Hadoop Streaming\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GtCRxFAwBAjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/hadoop-3.3.4/bin/hadoop jar /usr/local/hadoop-3.3.4/share/hadoop/tools/lib/hadoop-streaming-3.3.4.jar -input /root/input/input.txt -output ~/output -file /root/MapReduce/mapper.py  -file /root/MapReduce/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH_FOKSC9VOK",
        "outputId": "02292e8b-3bf3-4843-a2e7-77e10d12980c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-09 18:18:29,643 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
            "packageJobJar: [/root/MapReduce/mapper.py, /root/MapReduce/reducer.py] [] /tmp/streamjob15439843392751152654.jar tmpDir=null\n",
            "2022-10-09 18:18:30,524 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2022-10-09 18:18:30,764 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2022-10-09 18:18:30,764 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2022-10-09 18:18:30,790 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-10-09 18:18:31,000 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2022-10-09 18:18:31,027 INFO mapreduce.JobSubmitter: number of splits:1\n",
            "2022-10-09 18:18:31,472 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local269044035_0001\n",
            "2022-10-09 18:18:31,472 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2022-10-09 18:18:31,893 INFO mapred.LocalDistributedCacheManager: Localized file:/root/MapReduce/mapper.py as file:/tmp/hadoop-root/mapred/local/job_local269044035_0001_eb10bea8-6483-4e73-8e75-24f3dda08959/mapper.py\n",
            "2022-10-09 18:18:31,921 INFO mapred.LocalDistributedCacheManager: Localized file:/root/MapReduce/reducer.py as file:/tmp/hadoop-root/mapred/local/job_local269044035_0001_c4122c26-ce08-4699-9d3b-b269c1480677/reducer.py\n",
            "2022-10-09 18:18:32,097 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2022-10-09 18:18:32,100 INFO mapreduce.Job: Running job: job_local269044035_0001\n",
            "2022-10-09 18:18:32,109 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2022-10-09 18:18:32,111 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2022-10-09 18:18:32,118 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-09 18:18:32,118 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-09 18:18:32,192 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2022-10-09 18:18:32,198 INFO mapred.LocalJobRunner: Starting task: attempt_local269044035_0001_m_000000_0\n",
            "2022-10-09 18:18:32,272 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-09 18:18:32,274 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-09 18:18:32,328 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-10-09 18:18:32,355 INFO mapred.MapTask: Processing split: file:/root/input/input.txt:0+52\n",
            "2022-10-09 18:18:32,382 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2022-10-09 18:18:32,488 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-10-09 18:18:32,488 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-10-09 18:18:32,488 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-10-09 18:18:32,488 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-10-09 18:18:32,489 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-10-09 18:18:32,506 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-10-09 18:18:32,522 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2022-10-09 18:18:32,529 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2022-10-09 18:18:32,532 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2022-10-09 18:18:32,532 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2022-10-09 18:18:32,533 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2022-10-09 18:18:32,535 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2022-10-09 18:18:32,536 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2022-10-09 18:18:32,539 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2022-10-09 18:18:32,540 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2022-10-09 18:18:32,541 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2022-10-09 18:18:32,542 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2022-10-09 18:18:32,543 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2022-10-09 18:18:32,544 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2022-10-09 18:18:32,584 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:18:32,693 INFO streaming.PipeMapRed: Records R/W=4/1\n",
            "2022-10-09 18:18:32,695 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2022-10-09 18:18:32,695 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2022-10-09 18:18:32,705 INFO mapred.LocalJobRunner: \n",
            "2022-10-09 18:18:32,705 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-10-09 18:18:32,705 INFO mapred.MapTask: Spilling map output\n",
            "2022-10-09 18:18:32,705 INFO mapred.MapTask: bufstart = 0; bufend = 68; bufvoid = 104857600\n",
            "2022-10-09 18:18:32,705 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600\n",
            "2022-10-09 18:18:32,715 INFO mapred.MapTask: Finished spill 0\n",
            "2022-10-09 18:18:32,737 INFO mapred.Task: Task:attempt_local269044035_0001_m_000000_0 is done. And is in the process of committing\n",
            "2022-10-09 18:18:32,743 INFO mapred.LocalJobRunner: Records R/W=4/1\n",
            "2022-10-09 18:18:32,743 INFO mapred.Task: Task 'attempt_local269044035_0001_m_000000_0' done.\n",
            "2022-10-09 18:18:32,751 INFO mapred.Task: Final Counters for attempt_local269044035_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=2915\n",
            "\t\tFILE: Number of bytes written=642430\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=4\n",
            "\t\tMap output records=8\n",
            "\t\tMap output bytes=68\n",
            "\t\tMap output materialized bytes=90\n",
            "\t\tInput split bytes=78\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=8\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=29\n",
            "\t\tTotal committed heap usage (bytes)=308281344\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=52\n",
            "2022-10-09 18:18:32,751 INFO mapred.LocalJobRunner: Finishing task: attempt_local269044035_0001_m_000000_0\n",
            "2022-10-09 18:18:32,751 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2022-10-09 18:18:32,755 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2022-10-09 18:18:32,756 INFO mapred.LocalJobRunner: Starting task: attempt_local269044035_0001_r_000000_0\n",
            "2022-10-09 18:18:32,767 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-09 18:18:32,767 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-09 18:18:32,768 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-10-09 18:18:32,772 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@ef897a6\n",
            "2022-10-09 18:18:32,775 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-10-09 18:18:32,818 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2384042240, maxSingleShuffleLimit=596010560, mergeThreshold=1573467904, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2022-10-09 18:18:32,829 INFO reduce.EventFetcher: attempt_local269044035_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2022-10-09 18:18:32,894 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local269044035_0001_m_000000_0 decomp: 86 len: 90 to MEMORY\n",
            "2022-10-09 18:18:32,901 INFO reduce.InMemoryMapOutput: Read 86 bytes from map-output for attempt_local269044035_0001_m_000000_0\n",
            "2022-10-09 18:18:32,903 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 86, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->86\n",
            "2022-10-09 18:18:32,908 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2022-10-09 18:18:32,909 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-09 18:18:32,910 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2022-10-09 18:18:32,920 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-10-09 18:18:32,920 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 74 bytes\n",
            "2022-10-09 18:18:32,922 INFO reduce.MergeManagerImpl: Merged 1 segments, 86 bytes to disk to satisfy reduce memory limit\n",
            "2022-10-09 18:18:32,922 INFO reduce.MergeManagerImpl: Merging 1 files, 90 bytes from disk\n",
            "2022-10-09 18:18:32,923 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2022-10-09 18:18:32,923 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-10-09 18:18:32,925 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 74 bytes\n",
            "2022-10-09 18:18:32,926 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-09 18:18:32,941 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer.py]\n",
            "2022-10-09 18:18:32,953 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2022-10-09 18:18:32,956 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2022-10-09 18:18:32,997 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:18:33,107 INFO mapreduce.Job: Job job_local269044035_0001 running in uber mode : false\n",
            "2022-10-09 18:18:33,109 INFO streaming.PipeMapRed: Records R/W=8/1\n",
            "2022-10-09 18:18:33,110 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2022-10-09 18:18:33,115 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2022-10-09 18:18:33,115 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2022-10-09 18:18:33,116 INFO mapred.Task: Task:attempt_local269044035_0001_r_000000_0 is done. And is in the process of committing\n",
            "2022-10-09 18:18:33,118 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-09 18:18:33,118 INFO mapred.Task: Task attempt_local269044035_0001_r_000000_0 is allowed to commit now\n",
            "2022-10-09 18:18:33,121 INFO output.FileOutputCommitter: Saved output of task 'attempt_local269044035_0001_r_000000_0' to file:/root/output\n",
            "2022-10-09 18:18:33,124 INFO mapred.LocalJobRunner: Records R/W=8/1 > reduce\n",
            "2022-10-09 18:18:33,124 INFO mapred.Task: Task 'attempt_local269044035_0001_r_000000_0' done.\n",
            "2022-10-09 18:18:33,125 INFO mapred.Task: Final Counters for attempt_local269044035_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=3127\n",
            "\t\tFILE: Number of bytes written=642579\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=5\n",
            "\t\tReduce shuffle bytes=90\n",
            "\t\tReduce input records=8\n",
            "\t\tReduce output records=5\n",
            "\t\tSpilled Records=8\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=308281344\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=59\n",
            "2022-10-09 18:18:33,125 INFO mapred.LocalJobRunner: Finishing task: attempt_local269044035_0001_r_000000_0\n",
            "2022-10-09 18:18:33,125 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2022-10-09 18:18:34,111 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2022-10-09 18:18:34,112 INFO mapreduce.Job: Job job_local269044035_0001 completed successfully\n",
            "2022-10-09 18:18:34,125 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=6042\n",
            "\t\tFILE: Number of bytes written=1285009\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=4\n",
            "\t\tMap output records=8\n",
            "\t\tMap output bytes=68\n",
            "\t\tMap output materialized bytes=90\n",
            "\t\tInput split bytes=78\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=5\n",
            "\t\tReduce shuffle bytes=90\n",
            "\t\tReduce input records=8\n",
            "\t\tReduce output records=5\n",
            "\t\tSpilled Records=16\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=29\n",
            "\t\tTotal committed heap usage (bytes)=616562688\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=52\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=59\n",
            "2022-10-09 18:18:34,125 INFO streaming.StreamJob: Output directory: /root/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output"
      ],
      "metadata": {
        "id": "TTX-SOeZBjoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ~/output/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P1oso8t-Id1",
        "outputId": "74eb5657-5abe-4ccd-a9a8-3bf0f4f7c000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Afternoon\t1\n",
            "Evening\t1\n",
            "Good\t4\n",
            "Morning\t1\n",
            "Night\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. MapReduce Program in python to find sum of products sold in each country.\n",
        "\n",
        "### Step 1: Download the dataset needed\n",
        "\n",
        "### Step 2: Write Map Reduse Programs\n"
      ],
      "metadata": {
        "id": "JEN7lN9oBvUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /root/MapReduce/mapper2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n11lfLiElCB",
        "outputId": "d6875f28-33e0-42bf-9185-1507244edaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/usr/bin/env python\r\n",
            "\"\"\"mapper.py\"\"\"\r\n",
            "\r\n",
            "import sys\r\n",
            "\r\n",
            "# input comes from STDIN (standard input)\r\n",
            "for line in sys.stdin:\r\n",
            "    # remove leading and trailing whitespace\r\n",
            "    line = line.strip()\r\n",
            "    # split the line into words\r\n",
            "    words = line.split(',')\r\n",
            "    # increase counters\r\n",
            "    \r\n",
            "        # write the results to STDOUT (standard output);\r\n",
            "        # what we output here will be the input for the\r\n",
            "        # Reduce step, i.e. the input for reducer.py\r\n",
            "        #\r\n",
            "        # tab-delimited; the trivial word count is 1\r\n",
            "    print('%s\\t%s' % (words[7], 1))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /root/MapReduce/reducer2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25yvxfXtEtf5",
        "outputId": "58d37336-cafa-4ea0-eb3c-ba258d5a2e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/usr/bin/env python\r\n",
            "\"\"\"reducer.py\"\"\"\r\n",
            "\r\n",
            "from operator import itemgetter\r\n",
            "import sys\r\n",
            "\r\n",
            "current_word = None\r\n",
            "current_count = 0\r\n",
            "word = None\r\n",
            "\r\n",
            "# input comes from STDIN\r\n",
            "for line in sys.stdin:\r\n",
            "    # remove leading and trailing whitespace\r\n",
            "    line = line.strip()\r\n",
            "\r\n",
            "    # parse the input we got from mapper.py\r\n",
            "    word, count = line.split('\\t', 1)\r\n",
            "\r\n",
            "    # convert count (currently a string) to int\r\n",
            "    try:\r\n",
            "        count = int(count)\r\n",
            "    except ValueError:\r\n",
            "        # count was not a number, so silently\r\n",
            "        # ignore/discard this line\r\n",
            "        continue\r\n",
            "\r\n",
            "    # this IF-switch only works because Hadoop sorts map output\r\n",
            "    # by key (here: word) before it is passed to the reducer\r\n",
            "    if current_word == word:\r\n",
            "        current_count += count\r\n",
            "    else:\r\n",
            "        if current_word:\r\n",
            "            # write result to STDOUT\r\n",
            "            print('%s\\t%s' % (current_word, current_count))\r\n",
            "        current_count = count\r\n",
            "        current_word = word\r\n",
            "\r\n",
            "# do not forget to output the last word if needed!\r\n",
            "if current_word == word:\r\n",
            "    print('%s\\t%s' % (current_word, current_count))"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Execution"
      ],
      "metadata": {
        "id": "y-mnAoKmE2_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/hadoop-3.3.4/bin/hadoop jar /usr/local/hadoop-3.3.4/share/hadoop/tools/lib/hadoop-streaming-3.3.4.jar -input /root/input/SalesJan2009.csv -output ~/output2 -file /root/MapReduce/mapper2.py  -file /root/MapReduce/reducer2.py  -mapper 'python mapper2.py'  -reducer 'python reducer2.py'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5cxLdObE6qP",
        "outputId": "367c1ddd-1bd1-4764-c1f3-8c4ae35d1592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-09 18:50:48,177 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
            "packageJobJar: [/root/MapReduce/mapper2.py, /root/MapReduce/reducer2.py] [] /tmp/streamjob5228765212392933169.jar tmpDir=null\n",
            "2022-10-09 18:50:49,050 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2022-10-09 18:50:49,222 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2022-10-09 18:50:49,222 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2022-10-09 18:50:49,252 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-10-09 18:50:49,466 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2022-10-09 18:50:49,492 INFO mapreduce.JobSubmitter: number of splits:1\n",
            "2022-10-09 18:50:49,822 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local305976537_0001\n",
            "2022-10-09 18:50:49,822 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2022-10-09 18:50:50,357 INFO mapred.LocalDistributedCacheManager: Localized file:/root/MapReduce/mapper2.py as file:/tmp/hadoop-root/mapred/local/job_local305976537_0001_c7e2719f-4757-48c8-a850-ff5e49d1eac1/mapper2.py\n",
            "2022-10-09 18:50:50,404 INFO mapred.LocalDistributedCacheManager: Localized file:/root/MapReduce/reducer2.py as file:/tmp/hadoop-root/mapred/local/job_local305976537_0001_c2faed7b-a08e-4c6e-b88c-2b333f76e1d3/reducer2.py\n",
            "2022-10-09 18:50:50,556 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2022-10-09 18:50:50,559 INFO mapreduce.Job: Running job: job_local305976537_0001\n",
            "2022-10-09 18:50:50,570 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2022-10-09 18:50:50,573 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2022-10-09 18:50:50,600 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-09 18:50:50,600 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-09 18:50:50,689 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2022-10-09 18:50:50,696 INFO mapred.LocalJobRunner: Starting task: attempt_local305976537_0001_m_000000_0\n",
            "2022-10-09 18:50:50,782 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-09 18:50:50,785 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-09 18:50:50,852 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-10-09 18:50:50,897 INFO mapred.MapTask: Processing split: file:/root/input/SalesJan2009.csv:0+123637\n",
            "2022-10-09 18:50:50,924 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2022-10-09 18:50:51,154 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-10-09 18:50:51,154 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-10-09 18:50:51,154 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-10-09 18:50:51,154 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-10-09 18:50:51,154 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-10-09 18:50:51,160 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-10-09 18:50:51,181 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper2.py]\n",
            "2022-10-09 18:50:51,189 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2022-10-09 18:50:51,191 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2022-10-09 18:50:51,192 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2022-10-09 18:50:51,192 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2022-10-09 18:50:51,193 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2022-10-09 18:50:51,193 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2022-10-09 18:50:51,195 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2022-10-09 18:50:51,195 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2022-10-09 18:50:51,196 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2022-10-09 18:50:51,196 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2022-10-09 18:50:51,197 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2022-10-09 18:50:51,199 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2022-10-09 18:50:51,234 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:50:51,235 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:50:51,237 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:50:51,380 INFO streaming.PipeMapRed: Records R/W=999/1\n",
            "2022-10-09 18:50:51,400 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2022-10-09 18:50:51,400 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2022-10-09 18:50:51,406 INFO mapred.LocalJobRunner: \n",
            "2022-10-09 18:50:51,407 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-10-09 18:50:51,407 INFO mapred.MapTask: Spilling map output\n",
            "2022-10-09 18:50:51,407 INFO mapred.MapTask: bufstart = 0; bufend = 13745; bufvoid = 104857600\n",
            "2022-10-09 18:50:51,407 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26210404(104841616); length = 3993/6553600\n",
            "2022-10-09 18:50:51,439 INFO mapred.MapTask: Finished spill 0\n",
            "2022-10-09 18:50:51,482 INFO mapred.Task: Task:attempt_local305976537_0001_m_000000_0 is done. And is in the process of committing\n",
            "2022-10-09 18:50:51,487 INFO mapred.LocalJobRunner: Records R/W=999/1\n",
            "2022-10-09 18:50:51,488 INFO mapred.Task: Task 'attempt_local305976537_0001_m_000000_0' done.\n",
            "2022-10-09 18:50:51,499 INFO mapred.Task: Final Counters for attempt_local305976537_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=126501\n",
            "\t\tFILE: Number of bytes written=658122\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=999\n",
            "\t\tMap output records=999\n",
            "\t\tMap output bytes=13745\n",
            "\t\tMap output materialized bytes=15749\n",
            "\t\tInput split bytes=85\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=999\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=26\n",
            "\t\tTotal committed heap usage (bytes)=367001600\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=123637\n",
            "2022-10-09 18:50:51,499 INFO mapred.LocalJobRunner: Finishing task: attempt_local305976537_0001_m_000000_0\n",
            "2022-10-09 18:50:51,500 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2022-10-09 18:50:51,505 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2022-10-09 18:50:51,505 INFO mapred.LocalJobRunner: Starting task: attempt_local305976537_0001_r_000000_0\n",
            "2022-10-09 18:50:51,524 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-09 18:50:51,524 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-09 18:50:51,525 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-10-09 18:50:51,536 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@766e63b8\n",
            "2022-10-09 18:50:51,538 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-10-09 18:50:51,568 INFO mapreduce.Job: Job job_local305976537_0001 running in uber mode : false\n",
            "2022-10-09 18:50:51,571 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2022-10-09 18:50:51,576 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2384042240, maxSingleShuffleLimit=596010560, mergeThreshold=1573467904, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2022-10-09 18:50:51,581 INFO reduce.EventFetcher: attempt_local305976537_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2022-10-09 18:50:51,658 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local305976537_0001_m_000000_0 decomp: 15745 len: 15749 to MEMORY\n",
            "2022-10-09 18:50:51,665 INFO reduce.InMemoryMapOutput: Read 15745 bytes from map-output for attempt_local305976537_0001_m_000000_0\n",
            "2022-10-09 18:50:51,670 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 15745, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->15745\n",
            "2022-10-09 18:50:51,673 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2022-10-09 18:50:51,677 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-09 18:50:51,677 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2022-10-09 18:50:51,689 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-10-09 18:50:51,689 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 15733 bytes\n",
            "2022-10-09 18:50:51,699 INFO reduce.MergeManagerImpl: Merged 1 segments, 15745 bytes to disk to satisfy reduce memory limit\n",
            "2022-10-09 18:50:51,701 INFO reduce.MergeManagerImpl: Merging 1 files, 15749 bytes from disk\n",
            "2022-10-09 18:50:51,702 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2022-10-09 18:50:51,702 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-10-09 18:50:51,704 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 15733 bytes\n",
            "2022-10-09 18:50:51,705 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-09 18:50:51,723 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer2.py]\n",
            "2022-10-09 18:50:51,728 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2022-10-09 18:50:51,731 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2022-10-09 18:50:51,770 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:50:51,770 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:50:51,772 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:50:51,914 INFO streaming.PipeMapRed: Records R/W=999/1\n",
            "2022-10-09 18:50:51,921 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2022-10-09 18:50:51,922 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2022-10-09 18:50:51,923 INFO mapred.Task: Task:attempt_local305976537_0001_r_000000_0 is done. And is in the process of committing\n",
            "2022-10-09 18:50:51,927 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-09 18:50:51,927 INFO mapred.Task: Task attempt_local305976537_0001_r_000000_0 is allowed to commit now\n",
            "2022-10-09 18:50:51,930 INFO output.FileOutputCommitter: Saved output of task 'attempt_local305976537_0001_r_000000_0' to file:/root/output2\n",
            "2022-10-09 18:50:51,938 INFO mapred.LocalJobRunner: Records R/W=999/1 > reduce\n",
            "2022-10-09 18:50:51,939 INFO mapred.Task: Task 'attempt_local305976537_0001_r_000000_0' done.\n",
            "2022-10-09 18:50:51,940 INFO mapred.Task: Final Counters for attempt_local305976537_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=158031\n",
            "\t\tFILE: Number of bytes written=674548\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=58\n",
            "\t\tReduce shuffle bytes=15749\n",
            "\t\tReduce input records=999\n",
            "\t\tReduce output records=58\n",
            "\t\tSpilled Records=999\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=367001600\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=677\n",
            "2022-10-09 18:50:51,940 INFO mapred.LocalJobRunner: Finishing task: attempt_local305976537_0001_r_000000_0\n",
            "2022-10-09 18:50:51,940 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2022-10-09 18:50:52,577 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2022-10-09 18:50:52,578 INFO mapreduce.Job: Job job_local305976537_0001 completed successfully\n",
            "2022-10-09 18:50:52,594 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=284532\n",
            "\t\tFILE: Number of bytes written=1332670\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=999\n",
            "\t\tMap output records=999\n",
            "\t\tMap output bytes=13745\n",
            "\t\tMap output materialized bytes=15749\n",
            "\t\tInput split bytes=85\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=58\n",
            "\t\tReduce shuffle bytes=15749\n",
            "\t\tReduce input records=999\n",
            "\t\tReduce output records=58\n",
            "\t\tSpilled Records=1998\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=26\n",
            "\t\tTotal committed heap usage (bytes)=734003200\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=123637\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=677\n",
            "2022-10-09 18:50:52,596 INFO streaming.StreamJob: Output directory: /root/output2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output"
      ],
      "metadata": {
        "id": "QhErETreFheH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /root/output2/part-00000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYYPjTDoFjEh",
        "outputId": "91b8136b-a096-4e72-a874-aed1ea227f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Argentina\t1\n",
            "Australia\t38\n",
            "Austria\t7\n",
            "Bahrain\t1\n",
            "Belgium\t8\n",
            "Bermuda\t1\n",
            "Brazil\t5\n",
            "Bulgaria\t1\n",
            "CO\t1\n",
            "Canada\t76\n",
            "Cayman Isls\t1\n",
            "China\t1\n",
            "Costa Rica\t1\n",
            "Country\t1\n",
            "Czech Republic\t3\n",
            "Denmark\t15\n",
            "Dominican Republic\t1\n",
            "Finland\t2\n",
            "France\t27\n",
            "Germany\t25\n",
            "Greece\t1\n",
            "Guatemala\t1\n",
            "Hong Kong\t1\n",
            "Hungary\t3\n",
            "Iceland\t1\n",
            "India\t2\n",
            "Ireland\t49\n",
            "Israel\t1\n",
            "Italy\t15\n",
            "Japan\t2\n",
            "Jersey\t1\n",
            "Kuwait\t1\n",
            "Latvia\t1\n",
            "Luxembourg\t1\n",
            "Malaysia\t1\n",
            "Malta\t2\n",
            "Mauritius\t1\n",
            "Moldova\t1\n",
            "Monaco\t2\n",
            "Netherlands\t22\n",
            "New Zealand\t6\n",
            "Norway\t16\n",
            "Philippines\t2\n",
            "Poland\t2\n",
            "Romania\t1\n",
            "Russia\t1\n",
            "South Africa\t5\n",
            "South Korea\t1\n",
            "Spain\t12\n",
            "Sweden\t13\n",
            "Switzerland\t36\n",
            "Thailand\t2\n",
            "The Bahamas\t2\n",
            "Turkey\t6\n",
            "Ukraine\t1\n",
            "United Arab Emirates\t6\n",
            "United Kingdom\t100\n",
            "United States\t462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. MapReduce Program in python to find average sales ( AVG(price) ) per country.\n",
        "\n",
        "### Step 1: Download the dataset needed\n",
        "\n",
        "### Step 2: Write Map Reduse Programs"
      ],
      "metadata": {
        "id": "9DmpW2FVGK5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /root/MapReduce/mapper3.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mejIHiPnGnX0",
        "outputId": "654574cb-3988-492b-af68-8eae1da2dfcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/usr/bin/env python\r\n",
            "\"\"\"mapper.py\"\"\"\r\n",
            "\r\n",
            "import sys\r\n",
            "\r\n",
            "# input comes from STDIN (standard input)\r\n",
            "for line in sys.stdin:\r\n",
            "    # remove leading and trailing whitespace\r\n",
            "    line = line.strip()\r\n",
            "    # split the line into words\r\n",
            "    words = line.split(',')\r\n",
            "    # increase counters\r\n",
            "    \r\n",
            "        # write the results to STDOUT (standard output);\r\n",
            "        # what we output here will be the input for the\r\n",
            "        # Reduce step, i.e. the input for reducer.py\r\n",
            "        #\r\n",
            "        # tab-delimited; the trivial word count is 1\r\n",
            "    print('%s\\t%s' % (words[7], words[2]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /root/MapReduce/reducer3.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SFUX2OMGsBI",
        "outputId": "5e468de8-a353-4297-f89b-5b3926905170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/usr/bin/env python\r\n",
            "\"\"\"reducer.py\"\"\"\r\n",
            "\r\n",
            "from operator import itemgetter\r\n",
            "import sys\r\n",
            "\r\n",
            "current_word = None\r\n",
            "current_price = 0\r\n",
            "word = None\r\n",
            "count = 0\r\n",
            "\r\n",
            "# input comes from STDIN\r\n",
            "for line in sys.stdin:\r\n",
            "    # remove leading and trailing whitespace\r\n",
            "    line = line.strip()\r\n",
            "\r\n",
            "    # parse the input we got from mapper.py\r\n",
            "    word, price = line.split('\\t', 1)\r\n",
            "\r\n",
            "    # convert count (currently a string) to int\r\n",
            "    try:\r\n",
            "        price = int(price)\r\n",
            "    except ValueError:\r\n",
            "        # count was not a number, so silently\r\n",
            "        # ignore/discard this line\r\n",
            "        continue\r\n",
            "\r\n",
            "    # this IF-switch only works because Hadoop sorts map output\r\n",
            "    # by key (here: word) before it is passed to the reducer\r\n",
            "    if current_word == word:\r\n",
            "        count+=1\r\n",
            "        current_price += price\r\n",
            "    else:\r\n",
            "        if current_word:\r\n",
            "            # write result to STDOUT\r\n",
            "            print('%s\\t%s' % (current_word, current_price/count))\r\n",
            "        current_price = price\r\n",
            "        current_word = word\r\n",
            "        count = 1\r\n",
            "\r\n",
            "# do not forget to output the last word if needed!\r\n",
            "if current_word == word:\r\n",
            "    print('%s\\t%s' % (current_word, current_price/count))"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Execution"
      ],
      "metadata": {
        "id": "USN-xW6IGyb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/hadoop-3.3.4/bin/hadoop jar /usr/local/hadoop-3.3.4/share/hadoop/tools/lib/hadoop-streaming-3.3.4.jar -input /root/input/SalesJan2009.csv -output ~/output3 -file /root/MapReduce/mapper3.py  -file /root/MapReduce/reducer3.py  -mapper 'python mapper3.py'  -reducer 'python reducer3.py'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7FwDeTOG_Vg",
        "outputId": "07a28811-d5c8-425b-8d72-9b8b254de2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-09 18:58:10,040 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
            "packageJobJar: [/root/MapReduce/mapper3.py, /root/MapReduce/reducer3.py] [] /tmp/streamjob15755296827741900292.jar tmpDir=null\n",
            "2022-10-09 18:58:10,845 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2022-10-09 18:58:11,057 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2022-10-09 18:58:11,057 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2022-10-09 18:58:11,086 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-10-09 18:58:11,278 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2022-10-09 18:58:11,305 INFO mapreduce.JobSubmitter: number of splits:1\n",
            "2022-10-09 18:58:11,671 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1068172661_0001\n",
            "2022-10-09 18:58:11,671 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2022-10-09 18:58:12,219 INFO mapred.LocalDistributedCacheManager: Localized file:/root/MapReduce/mapper3.py as file:/tmp/hadoop-root/mapred/local/job_local1068172661_0001_da354bf5-9447-416a-9e9d-3c2ed6c0c033/mapper3.py\n",
            "2022-10-09 18:58:12,267 INFO mapred.LocalDistributedCacheManager: Localized file:/root/MapReduce/reducer3.py as file:/tmp/hadoop-root/mapred/local/job_local1068172661_0001_28f54cc1-05e9-47f4-9136-d5aa57161913/reducer3.py\n",
            "2022-10-09 18:58:12,418 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2022-10-09 18:58:12,421 INFO mapreduce.Job: Running job: job_local1068172661_0001\n",
            "2022-10-09 18:58:12,439 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2022-10-09 18:58:12,442 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2022-10-09 18:58:12,449 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-09 18:58:12,449 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-09 18:58:12,524 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2022-10-09 18:58:12,530 INFO mapred.LocalJobRunner: Starting task: attempt_local1068172661_0001_m_000000_0\n",
            "2022-10-09 18:58:12,580 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-09 18:58:12,580 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-09 18:58:12,645 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-10-09 18:58:12,661 INFO mapred.MapTask: Processing split: file:/root/input/SalesJan2009.csv:0+123637\n",
            "2022-10-09 18:58:12,711 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2022-10-09 18:58:12,839 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-10-09 18:58:12,839 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-10-09 18:58:12,839 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-10-09 18:58:12,839 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-10-09 18:58:12,839 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-10-09 18:58:12,847 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-10-09 18:58:12,889 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper3.py]\n",
            "2022-10-09 18:58:12,902 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2022-10-09 18:58:12,904 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2022-10-09 18:58:12,904 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2022-10-09 18:58:12,905 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2022-10-09 18:58:12,905 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2022-10-09 18:58:12,906 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2022-10-09 18:58:12,907 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2022-10-09 18:58:12,908 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2022-10-09 18:58:12,908 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2022-10-09 18:58:12,908 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2022-10-09 18:58:12,909 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2022-10-09 18:58:12,910 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2022-10-09 18:58:12,953 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:58:12,954 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:58:12,956 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:58:13,067 INFO streaming.PipeMapRed: Records R/W=999/1\n",
            "2022-10-09 18:58:13,091 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2022-10-09 18:58:13,092 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2022-10-09 18:58:13,098 INFO mapred.LocalJobRunner: \n",
            "2022-10-09 18:58:13,098 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-10-09 18:58:13,098 INFO mapred.MapTask: Spilling map output\n",
            "2022-10-09 18:58:13,098 INFO mapred.MapTask: bufstart = 0; bufend = 16740; bufvoid = 104857600\n",
            "2022-10-09 18:58:13,098 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26210404(104841616); length = 3993/6553600\n",
            "2022-10-09 18:58:13,134 INFO mapred.MapTask: Finished spill 0\n",
            "2022-10-09 18:58:13,153 INFO mapred.Task: Task:attempt_local1068172661_0001_m_000000_0 is done. And is in the process of committing\n",
            "2022-10-09 18:58:13,159 INFO mapred.LocalJobRunner: Records R/W=999/1\n",
            "2022-10-09 18:58:13,160 INFO mapred.Task: Task 'attempt_local1068172661_0001_m_000000_0' done.\n",
            "2022-10-09 18:58:13,170 INFO mapred.Task: Final Counters for attempt_local1068172661_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=126593\n",
            "\t\tFILE: Number of bytes written=664317\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=999\n",
            "\t\tMap output records=999\n",
            "\t\tMap output bytes=16740\n",
            "\t\tMap output materialized bytes=18744\n",
            "\t\tInput split bytes=85\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=999\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=42\n",
            "\t\tTotal committed heap usage (bytes)=374341632\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=123637\n",
            "2022-10-09 18:58:13,170 INFO mapred.LocalJobRunner: Finishing task: attempt_local1068172661_0001_m_000000_0\n",
            "2022-10-09 18:58:13,170 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2022-10-09 18:58:13,176 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2022-10-09 18:58:13,180 INFO mapred.LocalJobRunner: Starting task: attempt_local1068172661_0001_r_000000_0\n",
            "2022-10-09 18:58:13,199 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-09 18:58:13,203 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-09 18:58:13,204 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-10-09 18:58:13,213 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27384fa0\n",
            "2022-10-09 18:58:13,216 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-10-09 18:58:13,259 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2384042240, maxSingleShuffleLimit=596010560, mergeThreshold=1573467904, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2022-10-09 18:58:13,262 INFO reduce.EventFetcher: attempt_local1068172661_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2022-10-09 18:58:13,333 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1068172661_0001_m_000000_0 decomp: 18740 len: 18744 to MEMORY\n",
            "2022-10-09 18:58:13,338 INFO reduce.InMemoryMapOutput: Read 18740 bytes from map-output for attempt_local1068172661_0001_m_000000_0\n",
            "2022-10-09 18:58:13,343 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 18740, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->18740\n",
            "2022-10-09 18:58:13,347 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2022-10-09 18:58:13,349 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-09 18:58:13,349 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2022-10-09 18:58:13,360 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-10-09 18:58:13,360 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 18728 bytes\n",
            "2022-10-09 18:58:13,373 INFO reduce.MergeManagerImpl: Merged 1 segments, 18740 bytes to disk to satisfy reduce memory limit\n",
            "2022-10-09 18:58:13,374 INFO reduce.MergeManagerImpl: Merging 1 files, 18744 bytes from disk\n",
            "2022-10-09 18:58:13,376 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2022-10-09 18:58:13,376 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-10-09 18:58:13,378 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 18728 bytes\n",
            "2022-10-09 18:58:13,379 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-09 18:58:13,394 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer3.py]\n",
            "2022-10-09 18:58:13,401 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2022-10-09 18:58:13,406 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2022-10-09 18:58:13,440 INFO mapreduce.Job: Job job_local1068172661_0001 running in uber mode : false\n",
            "2022-10-09 18:58:13,441 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2022-10-09 18:58:13,450 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:58:13,450 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:58:13,451 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2022-10-09 18:58:13,581 INFO streaming.PipeMapRed: Records R/W=999/1\n",
            "2022-10-09 18:58:13,587 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2022-10-09 18:58:13,588 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2022-10-09 18:58:13,589 INFO mapred.Task: Task:attempt_local1068172661_0001_r_000000_0 is done. And is in the process of committing\n",
            "2022-10-09 18:58:13,591 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-09 18:58:13,591 INFO mapred.Task: Task attempt_local1068172661_0001_r_000000_0 is allowed to commit now\n",
            "2022-10-09 18:58:13,599 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1068172661_0001_r_000000_0' to file:/root/output3\n",
            "2022-10-09 18:58:13,601 INFO mapred.LocalJobRunner: Records R/W=999/1 > reduce\n",
            "2022-10-09 18:58:13,601 INFO mapred.Task: Task 'attempt_local1068172661_0001_r_000000_0' done.\n",
            "2022-10-09 18:58:13,602 INFO mapred.Task: Final Counters for attempt_local1068172661_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=164113\n",
            "\t\tFILE: Number of bytes written=684093\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=58\n",
            "\t\tReduce shuffle bytes=18744\n",
            "\t\tReduce input records=999\n",
            "\t\tReduce output records=56\n",
            "\t\tSpilled Records=999\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=374341632\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=1032\n",
            "2022-10-09 18:58:13,603 INFO mapred.LocalJobRunner: Finishing task: attempt_local1068172661_0001_r_000000_0\n",
            "2022-10-09 18:58:13,603 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2022-10-09 18:58:14,444 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2022-10-09 18:58:14,445 INFO mapreduce.Job: Job job_local1068172661_0001 completed successfully\n",
            "2022-10-09 18:58:14,460 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=290706\n",
            "\t\tFILE: Number of bytes written=1348410\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=999\n",
            "\t\tMap output records=999\n",
            "\t\tMap output bytes=16740\n",
            "\t\tMap output materialized bytes=18744\n",
            "\t\tInput split bytes=85\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=58\n",
            "\t\tReduce shuffle bytes=18744\n",
            "\t\tReduce input records=999\n",
            "\t\tReduce output records=56\n",
            "\t\tSpilled Records=1998\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=42\n",
            "\t\tTotal committed heap usage (bytes)=748683264\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=123637\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=1032\n",
            "2022-10-09 18:58:14,461 INFO streaming.StreamJob: Output directory: /root/output3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output"
      ],
      "metadata": {
        "id": "qOJBovUVHPq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /root/output3/part-00000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NbKCJDXHSWi",
        "outputId": "006bcab3-e62e-4cec-ad82-9b84770bc701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Argentina\t1200.0\n",
            "Australia\t1705.2631578947369\n",
            "Austria\t1542.857142857143\n",
            "Bahrain\t1200.0\n",
            "Belgium\t1500.0\n",
            "Bermuda\t1200.0\n",
            "Brazil\t2460.0\n",
            "Bulgaria\t1200.0\n",
            "Canada\t1642.1052631578948\n",
            "Cayman Isls\t1200.0\n",
            "China\t1200.0\n",
            "Costa Rica\t1200.0\n",
            "Czech Republic\t2000.0\n",
            "Denmark\t1200.0\n",
            "Dominican Republic\t1200.0\n",
            "Finland\t1200.0\n",
            "France\t1966.6666666666667\n",
            "Germany\t1680.0\n",
            "Greece\t1200.0\n",
            "Guatemala\t1200.0\n",
            "Hong Kong\t1200.0\n",
            "Hungary\t1200.0\n",
            "Iceland\t1200.0\n",
            "India\t1200.0\n",
            "Ireland\t1426.530612244898\n",
            "Israel\t1200.0\n",
            "Italy\t2520.0\n",
            "Japan\t1200.0\n",
            "Jersey\t1200.0\n",
            "Kuwait\t1200.0\n",
            "Latvia\t1200.0\n",
            "Luxembourg\t1200.0\n",
            "Malaysia\t1200.0\n",
            "Malta\t2400.0\n",
            "Mauritius\t3600.0\n",
            "Moldova\t1200.0\n",
            "Monaco\t1200.0\n",
            "Netherlands\t2031.8181818181818\n",
            "New Zealand\t1200.0\n",
            "Norway\t1350.0\n",
            "Philippines\t1200.0\n",
            "Poland\t1200.0\n",
            "Romania\t1200.0\n",
            "Russia\t3600.0\n",
            "South Africa\t2460.0\n",
            "South Korea\t1200.0\n",
            "Spain\t1400.0\n",
            "Sweden\t1753.8461538461538\n",
            "Switzerland\t2133.3333333333335\n",
            "Thailand\t2400.0\n",
            "The Bahamas\t1200.0\n",
            "Turkey\t1200.0\n",
            "Ukraine\t1200.0\n",
            "United Arab Emirates\t2000.0\n",
            "United Kingdom\t1440.0\n",
            "United States\t1595.2380952380952\n"
          ]
        }
      ]
    }
  ]
}